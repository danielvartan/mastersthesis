<!-- %:::% .common h1 begin %:::% -->
# Notes
<!-- %:::% .common h1 end %:::% -->

```{r}
#| label: setup
#| include: false

source(here::here("R/_setup.R"))
```

```{r}
#| echo: false
#| output: asis

rutils:::quarto_status(
  type = "polishing",
  of_what = "of this thesis",
  latex_parskip = "\\microskip"
  )
```

## About the data cleaning process

Data munging and wrangling processes were performed following the data science program proposed by @wickham2023b.

::: {#fig-wickham-at-al-2024-figure-1}
![](images/wickham-at-al-2024-figure-1.png){width=75%}

Source: Reproduced from @wickham2023b.

Model of the data science process created by Wickham, Çetinkaya-Runde, and Grolemund [-@wickham2023b].
:::

### Pipeline

Like this document, the data cleaning process is 100% reproducible. It can be audit by verifying the code in the `targets` pipeline use (see `./_targets.R`). Learn morea about the `targets` R package [here](https://books.ropensci.org/targets/).

### Lookup tables

Along with the data cleaning procedures, lookup tables were used to clean the text/character variables. These tables were created by manually inspecting the **unique values of the raw data** and adjusting common misspellings, synonyms, and other issues.

Text/character variables: `track`, `names`, `email`, `country`, `state`, `municiplality`, `postalcode`, `sleep_drugs_which`, `sleep_disorder_which`, `medication_which`.

The lookup tables are available in the research compendium of this thesis. They had to be encrypted because of the sensitive information they contain. If you need access, please contact the author.

The matching of the variables `sleep_drugs_which`, `sleep_disorder_which`, `medication_which` is not complete. This variables were not used in the analysis, but they are available in the research compendium.

Read the section about geographical information to learn more about the matching process.

## About the geographical information

Geographic data were collected by the variables `country`, `state`, `municipality`, and `postal code`. The unique values of those data were manually inspected and adjusted using lookup tables. The `municiplaity` values were first matched using string distance algorithms present in the [`stringdist`](https://github.com/markvanderloo/stringdist) R package and data from the Brazilian Institute of Geography and Statistics (IBGE) via the [`geobr`](https://ipeagit.github.io/geobr/index.html>) R package., other processes were then performed manually.

This was a hard task involving crossing information from different sources, such as the [QualoCEP](https://www.qualocep.com/), [Google Geocoding](https://developers.google.com/maps/documentation/geocoding/overview), [ViaCEP](https://viacep.com.br/), and [OpenStreetMap](https://www.openstreetmap.org/) databases, along with the Brazilian postal service ([Correios](https://www.correios.com.br/enviar/precisa-de-ajuda/tudo-sobre-cep)) postal code documentation. Hence, the data matching shown in the lookup table was gathered considering not only one variable, but the whole set of geographical information provided by the respondent. Special cases were coded in the lookup table named *special_cases*

All values were also checked for ambiguities, including the municipalities names (e.g., the name *Aracoiba* could refer to the municipality of *Aracoiaba* in the state of *Ceará*, but could also refer to the municipality of *Araçoiaba da Serra* in the state of *São Paulo*). All values that had a similarity or pattern matching with one or more municipalities were manually inspected to avoid errors (see `get_more_than_one_geographical_match` function in the code repository). 

### Postal codes

After removing all non-numeric characters from the Brazilian postal codes (Código de Endereçamento Postal ([CEP](https://pt.wikipedia.org/wiki/C%C3%B3digo_de_Endere%C3%A7amento_Postal))), they were processed by the following rules:

- If they had 9 or more digits, they were truncated to 8 digits (the first 8 digits are the postal code).
- If they between 5 and 7 digits, they were complemented with `0`s at the ending.
- If they had less than 5 digits, they were discarded.

In addition, a visual inspection was performed to check for inconsistencies.

After this process, the postal codes were matched with the [QualoCEP](https://www.qualocep.com/) database. Existing postal codes were than validated by the following rules:

- If the postal code had **not** been modified **and** the state **or** the municipality was the same, it was considered valid.
- If the postal code had been modified **and** the state and municipality were the same, it was considered valid.
- Else, it was considered invalid. Invalid CEPs were discarded in the processed dataset.

Invalid postal codes were then matched with data derived from reverse geocoding using [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/overview) via the [`tidygeocoder`](https://jessecambon.github.io/tidygeocoder/) R package, which is stored in the thesis lookup tables. After that, the same process of validation was performed. The postal codes that were not validated were discarded from the final data.

Finally, the `state` and `municipality` variables were adjusted using the data from the valid postal codes.

Non-Brazilian postal codes were not validated, but they were cleaned by removing non-digit characters and codes with 3 digits or less. They also went through a process da cleaning via visual inspection. Their values can be found in the `special_cases` lookup table.

## Latitudes and longitudes

Latitudes and longitudes values consider only the `municiplaity` and `postal_code` variables. They were extracted from the [QualoCEP](https://www.qualocep.com/) database, which is the result of a reverse geocoding using the [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/overview). See Appendice 6 to side by side comparison of the latitudes and longitudes from QualoCEP and Google Geocoding API.

For respondents  who did not provide a valid postal code, the latitude and longitude were extracted via the mean of the latitudes and longitudes associated with the municipality in the [QualoCEP](https://www.qualocep.com/) database.

Finally, [Google Geocoding API](https://developers.google.com/maps/documentation/geocoding/overview, via the [`tidygeocoder`](https://jessecambon.github.io/tidygeocoder/) R package, was used on cases that didn't had a match in the [QualoCEP](https://www.qualocep.com/) database.
